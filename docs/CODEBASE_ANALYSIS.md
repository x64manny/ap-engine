# AP-Engine Codebase Analysis

**Objective**: Clean repository to create a simple attack path generator that takes 5 parameters and generates an attack path - no bias, no hardcoded rules, no complex prompts.

**Target Input Format**:
```json
{
  "open_ports": [""],
  "services": [""],
  "applications": [""],
  "vulnerabilities": [{"cve": "", "score": ""}],
  "exposure": {
    "is_internet_exposed": "",
    "has_legacy_os": "",
    "has_admin_shares": ""
  }
}
```

---

## ğŸ“ File Inventory & Cleanup Recommendations

### Core Application Files

#### 1. `/app/main.py` - FastAPI Entry Point
**Current State**: 
- Multiple endpoints (`/health`, `/attack-path/main`, `/attack-path/markdown`)
- 7-stage attack path with stage-level continuity
- Markdown conversion logic (100+ lines)
- Hardcoded stage metadata and conversion

**Issues for Template**:
- âŒ Too specific - hardcoded 7-stage Cyber Kill Chain
- âŒ Markdown endpoint adds unnecessary complexity
- âŒ Continuity validation overhead
- âŒ Response model too complex (StageAnalysis, validation_report)

**Cleanup Actions**:
- âœ… **KEEP**: `/health` endpoint (minimal monitoring)
- âœ… **SIMPLIFY**: Single `/generate-attack-path` endpoint
- âŒ **REMOVE**: `/attack-path/markdown` endpoint
- âŒ **REMOVE**: Stage metadata hardcoding
- âŒ **REMOVE**: Markdown conversion logic (lines 100-200)

---

#### 2. `/app/config.py` - Configuration
**Current State**:
- Environment variable loading
- API metadata (title, version)
- LLM configuration (model, temperature)
- Validation method

**Issues for Template**:
- âš ï¸ Hardcoded API title: "Attack Path Engine"
- âš ï¸ LLM model defaults to "gpt-4o-mini"

**Cleanup Actions**:
- âœ… **KEEP**: Basic structure (env loading, LLM config)
- âœ… **SIMPLIFY**: Remove validation method (not needed for simple template)
- âš ï¸ **UPDATE**: API_TITLE to be generic or configurable

---

#### 3. `/app/core/prompts.py` - Prompt Builder (âš ï¸ CRITICAL - MAJOR BIAS)
**Current State**:
- 900+ line file with extensive hardcoded prompts
- SYSTEM_MESSAGE with 400+ lines of hardcoded rules
- Hardcoded "Granny Box IIS 6.0" reference example
- 7 stage-specific prompt builders with hardcoded Kill Chain methodology
- Hardcoded MITRE ATT&CK mappings
- Hardcoded Metasploit procedures and command syntax

**MAJOR ISSUES** (This is where ALL the bias lives):
- âŒ **Lines 15-200**: SYSTEM_MESSAGE with hardcoded IIS 6.0 exploitation example
- âŒ **Lines 200-350**: Hardcoded Cyber Kill Chain phases and detailed requirements
- âŒ **Lines 350-450**: Hardcoded Metasploit command syntax and procedures
- âŒ **Lines 450-550**: Hardcoded Windows/Linux/macOS command examples
- âŒ **Lines 550-900**: 7 separate stage builders (build_reconnaissance_prompt, build_weaponization_prompt, etc.)
- âŒ Each stage builder has hardcoded rules like "DO NOT plan attacks", "MUST reference Stage 2 artifact", etc.

**Cleanup Actions**:
- âŒ **DELETE ENTIRELY**: All 7 stage-specific builders
- âŒ **DELETE**: SYSTEM_MESSAGE (lines 15-500)
- âœ… **REPLACE WITH**: Simple, unbiased prompt builder
  ```python
  def build_attack_path_prompt(params: dict) -> str:
      return f"""Generate an attack path based on:
      - Open Ports: {params['open_ports']}
      - Services: {params['services']}
      - Applications: {params['applications']}
      - Vulnerabilities: {params['vulnerabilities']}
      - Exposure: {params['exposure']}
      
      Provide a realistic attack sequence."""
  ```

---

#### 4. `/app/models/attack_context.py` - Attack Context
**Current State**:
- Tracks 7 stage outputs (reconnaissance, weaponization, delivery, etc.)
- Artifact tracking dictionary
- Host data serialization

**Issues**:
- âŒ Hardcoded to 7-stage model
- âŒ Stage names are Kill Chain specific
- âŒ Artifact tracking adds complexity

**Cleanup Actions**:
- âŒ **DELETE ENTIRELY**: Not needed for simple template
- Replace with simple input/output models

---

#### 5. `/app/models/complete_analysis.py` - Response Models
**Current State**:
- StageAnalysis model (20+ fields)
- CompleteAnalysisResponse with validation_report
- Hardcoded stage metadata

**Issues**:
- âŒ Too complex - 20+ fields per stage
- âŒ Hardcoded MITRE techniques, tools, artifacts
- âŒ Validation report adds overhead

**Cleanup Actions**:
- âŒ **DELETE**: StageAnalysis complexity
- âœ… **REPLACE WITH**: Simple response model
  ```python
  class AttackPathResponse(BaseModel):
      request_id: str
      attack_path: str  # Simple text output
      execution_time: float
  ```

---

#### 6. `/app/models/host.py` - Input Models (âš ï¸ CRITICAL - WRONG SCHEMA)
**Current State**:
- Complex nested model: InputHost â†’ Service â†’ Vulnerability â†’ VulnerabilityInfo â†’ Classification
- 200+ lines of nested Pydantic models
- Fields: IpAddress, MacAddress, Os, Hostname, LastSeen, Services
- Each Service has: Port, Protocol, ServiceName, Product, Version, ExtraInfo, Vulnerabilities
- Each Vulnerability has: template_id, info, classification (CVE, CVSS, EPSS, etc.)

**MAJOR ISSUE**: 
- âŒ **COMPLETELY WRONG SCHEMA** - Does not match target input format
- âŒ Target needs: `open_ports`, `services`, `applications`, `vulnerabilities`, `exposure`
- âŒ Current has: `IpAddress`, `MacAddress`, `Os`, `Hostname`, `Services` (nested)

**Cleanup Actions**:
- âŒ **DELETE ENTIRELY**: All nested models (Service, Vulnerability, VulnerabilityInfo, Classification, Metadata)
- âœ… **REPLACE WITH**: Simple flat model matching target spec
  ```python
  class TargetInput(BaseModel):
      open_ports: List[str]
      services: List[str]
      applications: List[str]
      vulnerabilities: List[dict]  # [{"cve": "", "score": ""}]
      exposure: dict  # {"is_internet_exposed": "", ...}
  ```

---

#### 7. `/app/services/complete_analyzer.py` - Analysis Service (âš ï¸ MAJOR BIAS)
**Current State**:
- 500+ lines of hardcoded 7-stage workflow
- _generate_attack_path_with_continuity() method (lines 200-350)
- 7 sequential LLM calls with hardcoded prompt builders
- _parse_stage_response() with 200+ lines of regex extraction
- Artifact tracking and continuity validation
- Hardcoded stage names, phases, MITRE techniques

**Issues**:
- âŒ **Lines 200-350**: Hardcoded 7-stage sequential workflow
- âŒ **Lines 100-200**: Complex stage parsing with artifact extraction
- âŒ Hardcoded MITRE technique defaults (lines 50-100)
- âŒ Tool extraction with 10+ regex patterns

**Cleanup Actions**:
- âŒ **DELETE**: _generate_attack_path_with_continuity (entire method)
- âŒ **DELETE**: _parse_stage_response (entire method)
- âŒ **DELETE**: _extract_artifact_name (entire method)
- âŒ **DELETE**: Continuity validation logic
- âœ… **REPLACE WITH**: Simple single LLM call
  ```python
  async def analyze(self, target: TargetInput):
      prompt = self.prompt_builder.build(target)
      response = await self.llm_client.complete(prompt)
      return {"attack_path": response["content"]}
  ```

---

#### 8. `/app/services/llm_client.py` - LLM Client
**Current State**:
- LiteLLM integration
- Async completion method
- JSON mode support
- Token usage extraction

**Issues**:
- âœ… NO ISSUES - This is clean and reusable

**Cleanup Actions**:
- âœ… **KEEP AS-IS**: No changes needed

---

#### 9. `/app/utils/continuity_validator.py` - Validation
**Current State**:
- 300+ lines of artifact/CVE/technique validation
- Cross-stage continuity checks
- Tool consistency validation

**Issues**:
- âŒ Specific to 7-stage model
- âŒ Adds complexity and overhead

**Cleanup Actions**:
- âŒ **DELETE ENTIRELY**: Not needed for simple template

---

#### 10. `/app/utils/token_logger.py` - Token Logging
**Current State**:
- JSON Lines logging
- Token usage tracking
- Cost estimation
- Rotating file handler

**Issues**:
- âš ï¸ Hardcoded model costs (may be outdated)
- âœ… Otherwise useful for monitoring

**Cleanup Actions**:
- âœ… **KEEP**: Useful for monitoring
- âš ï¸ **UPDATE**: Model costs if needed

---

### Infrastructure Files

#### 11. `/requirements.txt`
**Current State**:
```
fastapi>=0.112
uvicorn[standard]>=0.30
pydantic>=2.7
httpx>=0.27
python-dotenv>=1.0
litellm>=1.40.0
tqdm>=4.66.1
```

**Cleanup Actions**:
- âœ… **KEEP ALL**: All dependencies are minimal and necessary
- â“ Consider removing `tqdm` if not used (progress bars)

---

#### 12. `/Dockerfile`
**Current State**:
- Python 3.10-slim base
- Non-root user
- Health check
- Uvicorn command

**Cleanup Actions**:
- âœ… **KEEP AS-IS**: Clean, minimal Dockerfile

---

#### 13. `/docker-compose.yml`
**Status**: Not read yet, but likely simple

**Cleanup Actions**:
- âœ… Review and simplify if needed

---

## ğŸ¯ Summary of Cleanup

### Files to DELETE Entirely
1. âŒ `/app/models/attack_context.py` - 7-stage specific
2. âŒ `/app/models/complete_analysis.py` - Complex stage models
3. âŒ `/app/utils/continuity_validator.py` - 7-stage validation

### Files to HEAVILY MODIFY
1. âš ï¸ `/app/core/prompts.py` - **900 lines â†’ ~50 lines**
   - Remove SYSTEM_MESSAGE (400+ lines)
   - Remove 7 stage builders
   - Replace with simple prompt builder
   
2. âš ï¸ `/app/models/host.py` - **200 lines â†’ ~20 lines**
   - Remove nested models
   - Replace with flat TargetInput matching spec
   
3. âš ï¸ `/app/services/complete_analyzer.py` - **500 lines â†’ ~50 lines**
   - Remove 7-stage workflow
   - Remove parsing logic
   - Simple single LLM call
   
4. âš ï¸ `/app/main.py` - **250 lines â†’ ~50 lines**
   - Remove markdown endpoint
   - Simplify response model
   - Single `/generate` endpoint

### Files to KEEP AS-IS
1. âœ… `/app/services/llm_client.py` - Clean
2. âœ… `/app/utils/token_logger.py` - Useful
3. âœ… `/app/config.py` - Minimal changes
4. âœ… `/Dockerfile` - Clean
5. âœ… `/requirements.txt` - Minimal

---

## ğŸ“Š Bias Concentration Map

**Highest Bias** (DELETE/REWRITE):
1. ğŸ”´ `/app/core/prompts.py` - 900 lines of hardcoded Kill Chain methodology
2. ğŸ”´ `/app/services/complete_analyzer.py` - 500 lines of 7-stage workflow
3. ğŸŸ¡ `/app/models/host.py` - Wrong schema, needs full replacement
4. ğŸŸ¡ `/app/models/complete_analysis.py` - Too complex, needs simplification

**Medium Bias** (SIMPLIFY):
5. ğŸŸ¡ `/app/main.py` - Endpoints and response handling

**No Bias** (KEEP):
6. ğŸŸ¢ `/app/services/llm_client.py`
7. ğŸŸ¢ `/app/utils/token_logger.py`
8. ğŸŸ¢ `/app/config.py`

---

## ğŸš€ Recommended Refactor Order

1. **Phase 1**: Delete unused files
   - Delete `attack_context.py`
   - Delete `complete_analysis.py`
   - Delete `continuity_validator.py`

2. **Phase 2**: Rewrite core models
   - Rewrite `host.py` â†’ `target_input.py` (new schema)
   - Create simple `attack_path_response.py`

3. **Phase 3**: Simplify prompts
   - Rewrite `prompts.py` (900 lines â†’ 50 lines)

4. **Phase 4**: Simplify analyzer
   - Rewrite `complete_analyzer.py` (500 lines â†’ 50 lines)

5. **Phase 5**: Update API
   - Simplify `main.py` endpoints

---

## ğŸ“ Target Architecture (Simple Template)

```
app/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py                    # Single endpoint: POST /generate
â”œâ”€â”€ config.py                  # Env config (keep as-is)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ target_input.py        # NEW: Simple 5-field model
â”‚   â””â”€â”€ response.py            # NEW: Simple response
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ attack_path_generator.py  # NEW: Single LLM call
â”‚   â””â”€â”€ llm_client.py          # KEEP: As-is
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ prompts.py             # REWRITE: Simple unbiased prompt
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ token_logger.py        # KEEP: As-is
```

**Total Lines**: ~300 lines (down from 3000+)

---

## âœ… Next Steps

1. Review this analysis
2. Confirm refactor approach
3. I'll implement the cleanup in phases
4. Test with sample input matching your spec

Ready to proceed?
